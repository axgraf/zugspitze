# Zugspitze - Metagenomik-Projekt ðŸ§¬â„ï¸  
*Erstellt von Alexander Graf Â· Letzte Aktualisierung: 05. Juli 2025*  
*Lesedauer: ca. 5 Minuten*

## ðŸ“„ Dokumentation

- Workflow-Dokumentation:  
  [https://epi2me.nanoporetech.com/epi2me-docs/workflows/wf-metagenomics/](https://epi2me.nanoporetech.com/epi2me-docs/workflows/wf-metagenomics/)

- Anleitung zur Nutzung eigener Referenzdatenbanken:  
  [https://epi2me.nanoporetech.com/how-to-meta-offline/](https://epi2me.nanoporetech.com/how-to-meta-offline/)

---

## ðŸ§¬ Referenzgenome

| Organismus | Taxonomy ID | Assembly | Level |
|-----------|-------------|----------|-------|
| *Lepus timidus* (Schneehase) | 62621 | [GCA_040893245.2](https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_040893245.2/) | Chromosome |
| *Lyrurus tetrix* (Birkhuhn) | 1233216 | [GCA_043882375.1](https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_043882375.1/) | Scaffold |
| *Lagopus muta* (Schneehuhn) | 64668 | [GCF_023343835.1](https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_023343835.1/) | Chromosome |


---

## âš™ï¸ Installation

```bash
# Conda Umgebung erstellen
mamba create -n zugspitze_metagenome \
  -c conda-forge -c bioconda \
  nextflow seqkit kraken2 pysam pandas plotly \
  --yes

mamba activate zugspitze_metagenome

# Docker installieren und aktivieren
sudo apt install docker.io
sudo systemctl enable --now docker
sudo usermod -aG docker $USER
newgrp docker

# Testlauf zur Installation des Workflows
nextflow run epi2me-labs/wf-metagenomics --help
```
---

## ðŸ§¬ Vorbereitung der Referenzgenome

Lade die Referenzgenomen fÃ¼r Schneehuhn (*Lagopus muta*), Birkhuhn (*Lyrurus tetrix*) und Schneehase (*Lepus timidus*) herunter und erstelle eine kombinierte FASTA-Datei sowie einen Minimap2-Index.

```bash
mkdir -p referenceGenome/{Lepus_timidus,Lagopus_muta,Lyrurus_tetrix,combined_genomes,taxdump}

# Genomdateien herunterladen
wget -P referenceGenome/Lepus_timidus https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/040/893/245/GCA_040893245.2_mLepTim1.1_pri/GCA_040893245.2_mLepTim1.1_pri_genomic.fna.gz
wget -P referenceGenome/Lagopus_muta https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/023/343/835/GCF_023343835.1_bLagMut1_primary/GCF_023343835.1_bLagMut1_primary_genomic.fna.gz
wget -P referenceGenome/Lyrurus_tetrix https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/043/882/375/GCA_043882375.1_ASM4388237v1/GCA_043882375.1_ASM4388237v1_genomic.fna.gz

# FASTA-Dateien zusammenfÃ¼hren
cat referenceGenome/Lepus_timidus/*.gz \
    referenceGenome/Lagopus_muta/*.gz \
    referenceGenome/Lyrurus_tetrix/*.gz \
    > referenceGenome/combined_genomes/LeTim_LagMut_LyrTet.genome.fasta.gz

# Minimap2-Index erzeugen
minimap2 -t 8 -x map-ont -d referenceGenome/combined_genomes/LeTim_LagMut_LyrTet.genome.mmi referenceGenome/combined_genomes/LeTim_LagMut_LyrTet.genome.fasta.gz

# Taxonomie-Datenbank herunterladen
wget -P referenceGenome/taxdump https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.tar.gz
```

---

## ðŸ“„ ref2taxid-Datei erzeugen

FÃ¼r die Klassifizierung mit Minimap2 benÃ¶tigt der Workflow eine Datei, die jede FASTA-Sequenz einem Taxonomie-Identifier zuordnet. Diese Datei wird manuell erzeugt:

```bash
cd referenceGenome/combined_genomes

# Lepus timidus (TaxID: 62621)
zgrep "^>" ../Lepus_timidus/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk '{print $0 "\t62621"}' > lepus.tsv

# Lagopus muta (TaxID: 64668)
zgrep "^>" ../Lagopus_muta/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk '{print $0 "\t64668"}' > lagopus.tsv

# Lyrurus tetrix (TaxID: 1233216)
zgrep "^>" ../Lyrurus_tetrix/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk '{print $0 "\t1233216"}' > lyrurus.tsv

# Alle EintrÃ¤ge zusammenfÃ¼hren
cat lepus.tsv lagopus.tsv lyrurus.tsv > ref2taxid.targloci.tsv
```

---

## ðŸ§­ Mapping-Datei fÃ¼r die Coverage-Analyse

FÃ¼r die spÃ¤tere Coverage-Visualisierung wird eine Mapping-Datei benÃ¶tigt, die jede FASTA-Sequenz einem der referenzierten Organismen und einem benannten Chromosomen- oder Contignamen zuordnet.

**Beispielzeile:**  
`NC_064433.1    Lagopus muta    chromosome_1`

Diese Datei wird Ã¼ber ein Shell-Skript erzeugt. Lege dazu das Skript `generate_mapping.sh` im Verzeichnis `referenceGenome/` an.

### Beispielinhalt fÃ¼r `generate_mapping.sh`

```bash
#!/bin/bash
mkdir -p mappings

zgrep "^>" Lepus_timidus/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk -F'.' '{print $0 "\tLepus timidus\t"$1}' > mappings/lepus.tsv
zgrep "^>" Lagopus_muta/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk -F'.' '{print $0 "\tLagopus muta\t"$1}' > mappings/lagopus.tsv
zgrep "^>" Lyrurus_tetrix/*.fna.gz | cut -d' ' -f1 | sed 's/^>//' | awk -F'.' '{print $0 "\tLyrurus tetrix\t"$1}' > mappings/lyrurus.tsv

cat mappings/lepus.tsv mappings/lagopus.tsv mappings/lyrurus.tsv > mappings/combined_mapping.tsv
```

### AusfÃ¼hrung des Skripts

FÃ¼hre das Mapping-Skript im Verzeichnis `referenceGenome` aus:

```bash
cd referenceGenome
chmod +x generate_mapping.sh
./generate_mapping.sh
```

## ðŸš€ Metagenome-Workflow von Epi2me mit Minimap2

Sobald alle Referenzdateien (Genom, Index, Taxonomie, `ref2taxid`, Mapping) vorbereitet sind, kann die Metagenomanalyse mit Minimap2 gestartet werden.

```bash
nextflow run epi2me-labs/wf-metagenomics \
  --fastq /pfad/zur/fastq_pass/ \
  --classifier minimap2 \
  --reference referenceGenome/combined_genomes/LeTim_LagMut_LyrTet.genome.mmi \
  --ref2taxid referenceGenome/combined_genomes/ref2taxid.targloci.tsv \
  --taxonomy referenceGenome/taxdump/new_taxdump.tar.gz \
  --out_dir zugspitze_output \
  --keep_bam
```

### Parameterbeschreibung

- ``--fastq``  
  Pfad zum Verzeichnis mit den demultiplexierten ONT-Reads, z.B. `fastq_pass/`

- ``--classifier minimap2``  
  Nutzt Minimap2 als Klassifikator (statt z.B. Kraken2)

- ``--reference``  
  Minimap2-Indexdatei (`.mmi`) der kombinierten Genome

- ``--ref2taxid``  
  TSV-Datei, die jede Sequenz-ID (z.B. `NC_...`) einer NCBI Taxonomy-ID zuordnet

- ``--taxonomy``  
  Komprimiertes Taxonomie-Archiv (`new_taxdump.tar.gz`) von NCBI

- ``--out_dir``  
  Zielordner fÃ¼r alle Ausgabedateien (Berichte, Klassifikation, BAMs)

- ``--keep_bam``  
  Behalte die ausgerichteten BAM-Dateien (notwendig fÃ¼r Coverage-Analyse)

---

## ðŸ§ª Automatisierte Analyse mit Minimap2

FÃ¼r die vollstÃ¤ndige automatisierte DurchfÃ¼hrung des Metagenomik-Workflows inklusive Coverage-Analyse kann das Bash-Skript [`run_metagenome_minimap2.sh`](./run_metagenome_minimap2.sh) verwendet werden.

### Aufruf:

```bash
./run_metagenome_minimap2.sh <FASTQ_INPUT_FOLDER> <OUTPUT_DIR> <SPECIES> [BIN_SIZE]
```

### Beispiel

```bash
./run_metagenome_minimap2.sh \
  20250626_1607_2F_PBE33297_9035ed7a/fastq_pass/ \
  zugspitze_analysis \
  "Lagopus muta" \
  1000
```

### Argumente

- `FASTQ_INPUT_FOLDER`  
  Pfad zum Ordner mit ONT-Fastq-Dateien, typischerweise der `fastq_pass/`-Ordner eines ONT-Runs.

- `OUTPUT_DIR`  
  Name oder Pfad des Ausgabeordners, in dem die Ergebnisse gespeichert werden.

- `SPECIES`  
  **Erforderlich.** Eine der folgenden Spezies (exakt in AnfÃ¼hrungszeichen angeben):  
  - `"Lagopus muta"`  
  - `"Lepus timidus"`  
  - `"Lyrurus tetrix"`

- `BIN_SIZE` *(optional)*  
  AuflÃ¶sung der Coverage-Binning-Fenster in Basen (z.â€¯B. `1000` fÃ¼r 1â€¯kb).  
  Wird kein Wert angegeben, wird `1000` als Standard verwendet.

---

## ðŸ“¦ Kraken2-Datenbank-Setup

FÃ¼r die Analyse mit Kraken2 wird eine vorgefertigte Klassifikationsdatenbank benÃ¶tigt. Die offiziellen Kraken2-Datenbanken sind vorkonfiguriert und kÃ¶nnen direkt verwendet werden.

> ðŸ”— Quelle: [https://benlangmead.github.io/aws-indexes/k2](https://benlangmead.github.io/aws-indexes/k2)

### Auswahl der passenden DatenbankgrÃ¶ÃŸe

Die Wahl der Datenbank hÃ¤ngt vom verfÃ¼gbaren Arbeitsspeicher ab:

- **PlusPFP-16** (`~14.9GB`)  
  Empfohlen bei â‰¥16â€“32GB RAM  
  EnthÃ¤lt:
  - RefSeq Archaea, Bacteria, Viruses, Plasmids
  - Human, UniVec_Core
  - **zusÃ¤tzlich**: RefSeq Protozoa, Pilze (Fungi), Pflanzen (Plants)

- **PlusPFP-8** (`~7.5GB`)  
  Empfohlen bei 8GB RAM  
  Gleicher Aufbau wie PlusPFP-16, aber reduzierter Umfang

> ðŸ’» *Hinweis:* Auf einem Laptop mit 32GB RAM wurde im Projekt `PlusPFP-16` erfolgreich verwendet.

---

### Download von PlusPFP-16

```bash
mkdir -p referenceGenome/kraken2_db/k2_pluspf_16gb
cd referenceGenome/kraken2_db/k2_pluspf_16gb

wget https://genome-idx.s3.amazonaws.com/kraken/k2_pluspf_16gb_20250402.tar.gz
tar -xf k2_pluspf_16gb_20250402.tar.gz
```

---

## ðŸš€ Analyse mit Kraken2

Nach dem Setup der Kraken2-Datenbank und des NCBI-Taxonomiearchivs kann der Workflow mit Kraken2 als Klassifikator gestartet werden.

### Beispiel: Manuelle AusfÃ¼hrung

```bash
nextflow run epi2me-labs/wf-metagenomics \
  --fastq /data/20250626_DNA_Test_Schneehuhn/20250626_DNA_Test_Schneehuhn/20250626_1607_2F_PBE33297_9035ed7a/fastq_pass/ \
  --database referenceGenome/kraken2_db/k2_pluspf_16gb/ \
  --taxonomy referenceGenome/kraken2_db/taxonomy/ \
  --out_dir zugspitze_kraken2
```

### Parameterbeschreibung

- `--fastq`  
  Pfad zum Verzeichnis mit den demultiplexierten ONT-Fastq-Dateien (z.B. `fastq_pass/`)

- `--database`  
  Pfad zur entpackten Kraken2-Datenbank (z.B. `referenceGenome/kraken2_db/k2_pluspf_16gb/`)

- `--taxonomy`  
  Pfad zum Verzeichnis mit den entpackten NCBI-Taxonomiedaten (aus `new_taxdump.tar.gz`)

- `--out_dir`  
  Zielordner fÃ¼r die Analyseergebnisse (z.B. `zugspitze_kraken2`)

---

## ðŸ§ª Automatisierter Workflow mit Kraken2

FÃ¼r eine automatisierte Analyse mit Kraken2 kann das Skript [`run_metagenome_kraken2.sh`](./run_metagenome_kraken2.sh) verwendet werden.  
Es ruft den Nextflow-Workflow mit den im Skript definierten Datenbank- und Taxonomie-Pfaden auf.

### Aufruf

```bash
./run_metagenome_kraken2.sh <FASTQ_INPUT_FOLDER> <OUTPUT_DIR>
```

### Argumente

- `FASTQ_INPUT_FOLDER`  
  Pfad zum Ordner mit ONT-Fastq-Dateien, typischerweise `fastq_pass/`

- `OUTPUT_DIR`  
  Verzeichnis, in dem die Ergebnisse gespeichert werden (wird bei Bedarf automatisch angelegt)

### Hinweise

- Die im Skript verwendeten Pfade zur Kraken2-Datenbank und zur Taxonomie mÃ¼ssen existieren und korrekt gesetzt sein:

  ```bash
  KRAKEN2_DB="referenceGenome/kraken2_db/k2_pluspf_16gb/"
  TAXONOMY="referenceGenome/kraken2_db/taxonomy/"
  ```
  
